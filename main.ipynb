{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "実行時に設定するパラメータ\n",
    "\"\"\"\n",
    "\n",
    "# Informerの学習パラメータ\n",
    "# Informerを学習するときに使用したパラメータの文字列をここで代入する\n",
    "#ARG_STR = \"--model informer --data ETTh1 --attn prob --freq h --checkpoints 'checkpoints/ETTh1_sample30_window30' --features S  --e_layers 1  --d_layers 1 --dropout 0.3 --learning_rate 0.0001 --embed timeF\"\n",
    "ARG_STR = \"--model informer --data NaturalGas --root_path './Informer2020/data/NaturalGas/' --data_path combined_data.csv --features S --attn prob --freq h --checkpoints 'checkpoints/NaturalGas_sample30_window30' --e_layers 1  --d_layers 1 --dropout 0.3 --learning_rate 0.0001 --embed timeF\"\n",
    "\n",
    "# 学習済みのInformerモデルが保存されているパス\n",
    "INFORMER_CKPT_PATH = \"checkpoints/informer-small.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fcd3wr3l3rnn"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"Informer2020\")\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import dataset\n",
    "from model.informer_model import InformerModel\n",
    "from model.model import Model\n",
    "from model.moment_model import MomentModel\n",
    "from propose import ProposedModelWithMoe, ProposedModel\n",
    "from evaluation import evaluate_mse, evaluate_nll\n",
    "\n",
    "from main_informer import parse_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kHpNHeCC3rnq"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int) -> None:\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # pytorch\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.mps.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def load_moment_model(args: argparse.Namespace) -> Model:\n",
    "    return MomentModel(param=\"AutonLab/MOMENT-1-large\", pred_len=args.pred_len)\n",
    "\n",
    "\n",
    "def load_moment_model_finetuned(\n",
    "    args: argparse.Namespace,\n",
    "    train_dataset: torch.utils.data.Dataset,\n",
    "    valid_dataset: torch.utils.data.Dataset,\n",
    ") -> Model:\n",
    "    model: MomentModel = load_moment_model(args=args)\n",
    "    model.fine_tuning(train_dataset=train_dataset, valid_dataset=valid_dataset, args=args)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_informer_model(args: argparse.Namespace) -> Model:\n",
    "    return InformerModel(args, checkpoint_path=INFORMER_CKPT_PATH)\n",
    "\n",
    "\n",
    "def load_proposed_model(moment_model: Model, informer_model: Model) -> Model:\n",
    "    model = ProposedModel(moment_model=moment_model, informer_model=informer_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_proposed_model_with_moe(\n",
    "    moment_model: Model,\n",
    "    informer_model: Model,\n",
    "    input_size: int,\n",
    "    train_dataset: torch.utils.data.Dataset,\n",
    "    valid_dataset: torch.utils.data.Dataset,\n",
    "    args: argparse.Namespace,\n",
    ") -> Model:\n",
    "    model = ProposedModelWithMoe(\n",
    "        moment_model=moment_model,\n",
    "        informer_model=informer_model,\n",
    "        input_size=input_size,\n",
    "    )\n",
    "    model.train(train_dataset=train_dataset, valid_dataset=valid_dataset, args=args)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bcEvNf_e3rnr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(model='informer', data='NaturalGas', root_path='./Informer2020/data/NaturalGas/', data_path='combined_data.csv', features='S', target='actual_wdl_gj', freq='h', checkpoints='checkpoints/NaturalGas_sample30_window30', seq_len=96, label_len=48, pred_len=24, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=1, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.3, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=2, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "[test] self.target actual_wdl_gj\n",
      "[test] cols ['date', 'schedule_interval', 'transmission_id', 'sched_inj_gj', 'sched_wdl_gj', 'price_value', 'administered_price', 'actual_wdl_gj', 'actual_inj_gj']\n",
      "train 6275\n",
      "[test] self.target actual_wdl_gj\n",
      "[test] cols ['date', 'schedule_interval', 'transmission_id', 'sched_inj_gj', 'sched_wdl_gj', 'price_value', 'administered_price', 'actual_wdl_gj', 'actual_inj_gj']\n",
      "val 891\n",
      "[test] self.target actual_wdl_gj\n",
      "[test] cols ['date', 'schedule_interval', 'transmission_id', 'sched_inj_gj', 'sched_wdl_gj', 'price_value', 'administered_price', 'actual_wdl_gj', 'actual_inj_gj']\n",
      "test 1804\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Informer:\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([16, 1, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for enc_embedding.position_embedding.pe: copying a param with shape torch.Size([1, 5000, 16]) from checkpoint, the shape in current model is torch.Size([1, 5000, 512]).\n\tsize mismatch for enc_embedding.temporal_embedding.embed.weight: copying a param with shape torch.Size([16, 4]) from checkpoint, the shape in current model is torch.Size([512, 4]).\n\tsize mismatch for enc_embedding.temporal_embedding.embed.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([16, 1, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for dec_embedding.position_embedding.pe: copying a param with shape torch.Size([1, 5000, 16]) from checkpoint, the shape in current model is torch.Size([1, 5000, 512]).\n\tsize mismatch for dec_embedding.temporal_embedding.embed.weight: copying a param with shape torch.Size([16, 4]) from checkpoint, the shape in current model is torch.Size([512, 4]).\n\tsize mismatch for dec_embedding.temporal_embedding.embed.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.conv1.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1]).\n\tsize mismatch for encoder.attn_layers.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.attn_layers.0.conv2.weight: copying a param with shape torch.Size([16, 32, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1]).\n\tsize mismatch for encoder.attn_layers.0.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.norm.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.norm.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.conv1.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1]).\n\tsize mismatch for decoder.layers.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decoder.layers.0.conv2.weight: copying a param with shape torch.Size([16, 32, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1]).\n\tsize mismatch for decoder.layers.0.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.norm.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.norm.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for projection.weight: copying a param with shape torch.Size([1, 16]) from checkpoint, the shape in current model is torch.Size([1, 512]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m input_size \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mseq_len\n\u001b[1;32m     12\u001b[0m moment_model \u001b[38;5;241m=\u001b[39m load_moment_model(args\u001b[38;5;241m=\u001b[39margs)\n\u001b[0;32m---> 13\u001b[0m informer_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_informer_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m proposed_model \u001b[38;5;241m=\u001b[39m load_proposed_model(moment_model, informer_model,input_size,train_dataset,args)\n",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m, in \u001b[0;36mload_informer_model\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_informer_model\u001b[39m(args: argparse\u001b[38;5;241m.\u001b[39mNamespace) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mInformerModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINFORMER_CKPT_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/informer-moment/model/informer_model.py:45\u001b[0m, in \u001b[0;36mInformerModel.__init__\u001b[0;34m(self, args, checkpoint_path)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     41\u001b[0m     args: argparse\u001b[38;5;241m.\u001b[39mNamespace,\n\u001b[1;32m     42\u001b[0m     checkpoint_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     43\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m load_default_informer(args)\n\u001b[0;32m---> 45\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_pred \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/dev/informer-moment/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:2584\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2576\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2577\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2578\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2579\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2580\u001b[0m             ),\n\u001b[1;32m   2581\u001b[0m         )\n\u001b[1;32m   2583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2584\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2586\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2587\u001b[0m         )\n\u001b[1;32m   2588\u001b[0m     )\n\u001b[1;32m   2589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Informer:\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([16, 1, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for enc_embedding.value_embedding.tokenConv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for enc_embedding.position_embedding.pe: copying a param with shape torch.Size([1, 5000, 16]) from checkpoint, the shape in current model is torch.Size([1, 5000, 512]).\n\tsize mismatch for enc_embedding.temporal_embedding.embed.weight: copying a param with shape torch.Size([16, 4]) from checkpoint, the shape in current model is torch.Size([512, 4]).\n\tsize mismatch for enc_embedding.temporal_embedding.embed.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.weight: copying a param with shape torch.Size([16, 1, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3]).\n\tsize mismatch for dec_embedding.value_embedding.tokenConv.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for dec_embedding.position_embedding.pe: copying a param with shape torch.Size([1, 5000, 16]) from checkpoint, the shape in current model is torch.Size([1, 5000, 512]).\n\tsize mismatch for dec_embedding.temporal_embedding.embed.weight: copying a param with shape torch.Size([16, 4]) from checkpoint, the shape in current model is torch.Size([512, 4]).\n\tsize mismatch for dec_embedding.temporal_embedding.embed.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for encoder.attn_layers.0.attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.conv1.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1]).\n\tsize mismatch for encoder.attn_layers.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for encoder.attn_layers.0.conv2.weight: copying a param with shape torch.Size([16, 32, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1]).\n\tsize mismatch for encoder.attn_layers.0.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.attn_layers.0.norm2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.norm.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for encoder.norm.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.self_attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.self_attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.query_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.query_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.key_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.key_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.value_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.value_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.cross_attention.out_projection.weight: copying a param with shape torch.Size([16, 16]) from checkpoint, the shape in current model is torch.Size([512, 512]).\n\tsize mismatch for decoder.layers.0.cross_attention.out_projection.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.conv1.weight: copying a param with shape torch.Size([32, 16, 1]) from checkpoint, the shape in current model is torch.Size([2048, 512, 1]).\n\tsize mismatch for decoder.layers.0.conv1.bias: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([2048]).\n\tsize mismatch for decoder.layers.0.conv2.weight: copying a param with shape torch.Size([16, 32, 1]) from checkpoint, the shape in current model is torch.Size([512, 2048, 1]).\n\tsize mismatch for decoder.layers.0.conv2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm1.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm2.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.layers.0.norm3.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.norm.weight: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.norm.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for projection.weight: copying a param with shape torch.Size([1, 16]) from checkpoint, the shape in current model is torch.Size([1, 512])."
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "args = parse_args(ARG_STR)\n",
    "save_file_name = args.checkpoints\n",
    "if not os.path.exists(save_file_name):\n",
    "    os.mkdir(save_file_name)\n",
    "print(\"args:\", args)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = dataset.load_dataset(args=args)\n",
    "input_size = args.seq_len\n",
    "\n",
    "moment_model = load_moment_model(args=args)\n",
    "informer_model = load_informer_model(args=args)\n",
    "proposed_model = load_proposed_model(moment_model, informer_model,input_size,train_dataset,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 196/196 [08:43<00:00,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Loss: 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "proposed_model_with_moe = load_proposed_model_with_moe(moment_model, informer_model,input_size,train_dataset,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "deEQ5j5l3rns"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args: Namespace(model='informer', data='NaturalGas', root_path='./Informer2020/data/NaturalGas/', data_path='combined_data.csv', features='S', target='actual_wdl_gj', freq='h', checkpoints='checkpoints/NaturalGas_sample30_window30', seq_len=96, label_len=48, pred_len=24, enc_in=1, dec_in=1, c_out=1, d_model=512, n_heads=8, e_layers=1, d_layers=1, s_layers=[3, 2, 1], d_ff=2048, factor=5, padding=0, distil=True, dropout=0.3, attn='prob', embed='timeF', activation='gelu', output_attention=False, do_predict=False, mix=True, cols=None, num_workers=0, itr=2, train_epochs=6, batch_size=32, patience=3, learning_rate=0.0001, des='test', loss='mse', lradj='type1', use_amp=False, inverse=False, use_gpu=False, gpu=0, use_multi_gpu=False, devices='0,1,2,3', detail_freq='h')\n",
      "testing: informer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:51<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.2771660422917495, 'nll': 211.86042112751724}\n",
      "testing: moment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [1:14:28<00:00, 79.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.2898083649419951, 'nll': 237.83403569447142}\n",
      "testing: proposed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [1:18:16<00:00, 83.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.26338581409654455, 'nll': 175.2089096087653}\n",
      "testing: proposed+moe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [1:18:21<00:00, 83.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mse': 0.2735648845773251, 'nll': 440.9727333241699}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'informer': {'mse': 0.2771660422917495, 'nll': 211.86042112751724},\n",
       " 'moment': {'mse': 0.2898083649419951, 'nll': 237.83403569447142},\n",
       " 'proposed': {'mse': 0.26338581409654455, 'nll': 175.2089096087653},\n",
       " 'proposed+moe': {'mse': 0.2735648845773251, 'nll': 440.9727333241699}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 予測結果の評価\n",
    "print(\"args:\", args)\n",
    "results = {}\n",
    "\n",
    "for method, model in {\n",
    "    \"informer\": informer_model,\n",
    "    \"moment\": moment_model,\n",
    "    \"proposed\": proposed_model,\n",
    "    \"proposed+moe\": proposed_model_with_moe,\n",
    "}.items():\n",
    "    print(f\"testing: {method}\")\n",
    "    test_dataloader = dataset.to_dataloader(test_dataset, args, \"test\")\n",
    "\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    for index, batch in tqdm.tqdm(test_dataloader):\n",
    "        y_pred.append(model.predict_distr(batch).detach().tolist())\n",
    "        y_true.append(batch[1][:, -1].squeeze().detach().tolist())\n",
    "\n",
    "    y_pred, y_true = np.array(y_pred).reshape(-1, 2), np.array(y_true).flatten()\n",
    "    results[method] = {\n",
    "        \"mse\": evaluate_mse(y_pred, y_true),\n",
    "        \"nll\": evaluate_nll(y_pred, y_true),\n",
    "    }\n",
    "    print(results[method])\n",
    "\n",
    "    np.save(f\"checkpoints/{args.data}/y_pred_{method}.npy\", y_pred)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).to_csv(\"results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
